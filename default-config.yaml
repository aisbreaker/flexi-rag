#
# configure the Retrieval Augmented Generation system here
# (in this file are the default settings/default values)
#
config:
  common:
    chat_llms:
      ChatOpenAI_default_llm:
        # class=<module>.<chat-class>
        class: langchain_openai.ChatOpenAI
        args:
          # you can overwrite, e.g. "model_name" with environment variable:
          #   export RAG_CONFIG__COMMON__DEFAULT_LLM_WITH_STREAMING__ChatOpenAI__args__model_name="gpt-ais-invalid-model"
          model_name: "gpt-4o-mini"
          temperature: 0.2
          streaming: False

      ChatOpenAI_default_llm_with_streaming:
        class: langchain_openai.ChatOpenAI
        args:
          model_name: "gpt-4o-mini"
          temperature: 0.2
          streaming: True

      ChatOpenAI_strict_llm:
        class: langchain_openai.ChatOpenAI
        args:
          model_name: "gpt-4o-mini"
          temperature: 0
          streaming: False

    databases:
      vectorstore:
        # class=<module>.<chat-class>
        class: langchain_community.vectorstores.Chroma
        args:
          persist_directory: "./chroma_db"
          collection_name: "rag-chroma"
        embedding_function_arg_name: embedding_function


  rag_index_service:
    enabled: true
  crawling:
    enabled: true
    depth: 3
    max_pages: 1000


  rag_response_service:
    default_chat_llm: ChatOpenAI_default_llm
    default_chat_llm_with_streaming: ChatOpenAI_default_llm_with_streaming
    document_grader_chat_llm: ChatOpenAI_strict_llm
    rewrite_question_chat_llm: ChatOpenAI_strict_llm


  embedding_and_indexing:
    enabled: true
    embedding_model: "bert-base-uncased"
    index_path: "/data/aisbreaker-workspace/hapkecom-github/flexi-rag/index"

  vector_search:
    enabled: true
    index_path: "/data/aisbreaker-workspace/hapkecom-github/flexi-rag/index"
    similarity_threshold: 0.7

  string_keyword_search:
    enabled: true
    index_path: "/data/aisbreaker-workspace/hapkecom-github/flexi-rag/index"

  final_llm_processing:
    enabled: true
    model: "gpt2"
    max_length: 100
    temperature: 0.8


# test entries without any semantics:
test:
  value: 1
  valuestr: "test"
